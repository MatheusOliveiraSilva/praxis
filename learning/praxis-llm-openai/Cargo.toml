[package]
name = "praxis-llm-openai"
version = "0.1.0"
edition = "2021"

[dependencies]
# Async runtime
tokio = { version = "1", features = ["full"] }
async-trait = "0.1"

# HTTP client (rustls to avoid OpenSSL dependency)
reqwest = { version = "0.12", default-features = false, features = ["json", "stream", "rustls-tls"] }

# Serialization
serde = { version = "1", features = ["derive"] }
serde_json = "1"

# Streaming utilities
futures = "0.3"
tokio-stream = "0.1"
async-stream = "0.3"

# Error handling
thiserror = "1"
anyhow = "1"

# Utils
chrono = "0.4"

[[example]]
name = "01_chat"
path = "examples/01_chat.rs"

[[example]]
name = "02_chat_streaming"
path = "examples/02_chat_streaming.rs"

[[example]]
name = "03_reasoning"
path = "examples/03_reasoning.rs"

[[example]]
name = "04_reasoning_streaming"
path = "examples/04_reasoning_streaming.rs"
